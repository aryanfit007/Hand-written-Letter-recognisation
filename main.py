# -*- coding: utf-8 -*-
"""main.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/107iOmlW3m75aXG8vmsZofRHBBa5Km2uW
"""

from google.colab import drive
drive.mount('/content/gdrive')

# import models
import os
import cv2
import torch
from torch.nn.functional import normalize
import numpy as np
import pandas as pd
import seaborn as sns
import torch.nn as  nn
import matplotlib.pyplot as plt

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

if __name__ == "__main__":

  class CNNModel(nn.Module):
      def __init__(self):
          super(CNNModel,self).__init__()

          #Convolution :
          self.cnn1 = nn.Conv2d(in_channels = 1 ,out_channels = 16 , kernel_size = 3, stride = 1 , padding = 0)
          self.relu1 = nn.ReLU()
          self.maxpool1 = nn.MaxPool2d(kernel_size = (2,2))

          #Convolution 2
          self.cnn2 = nn.Conv2d(in_channels = 16 ,out_channels = 32 , kernel_size = 3, stride = 1 , padding = 0)
          self.relu2 = nn.ReLU()
          self.maxpool2 = nn.MaxPool2d(kernel_size =2 )

          self.fc1 = nn.Linear(in_features=800, out_features=500)
          self.relu3 = nn.ReLU()

          self.fc2 = nn.Linear(500,27)          
          
      def forward(self,x):
          out = self.cnn1(x)
          out = self.relu1(out)
          out = self.maxpool1(out)

          out = self.cnn2(out)
          out = self.relu2(out)
          out = self.maxpool2(out)

          out = out.view(out.size(0),-1)

          out = self.fc1(out)
          out = self.relu3(out)

          out = self.fc2(out)

          return out

  # Evaluating letter_model
  letter_model = CNNModel()
  letter_model.load_state_dict(torch.load('/content/gdrive/MyDrive/MOSAIC_PS1(UCHIHA)_SUBMISSION/letters.h5'))
  letter_model.eval()

  # Image segmentation
  def segmentCaptcha(img):
    img = cv2.resize(img, (800,300), interpolation = cv2.INTER_AREA)
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, th1 = cv2.threshold(img_gray,190, 255, cv2.THRESH_BINARY_INV)
    kernel = np.ones((5,5), dtype = np.uint8)
    img_dil = cv2.dilate(th1, kernel, iterations=2)

    contours, _ = cv2.findContours(img_dil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    
    sorted_ctrs = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])
    img_crops = []
    k=0
    for i, ctr in enumerate(sorted_ctrs):
        x, y, w, h = cv2.boundingRect(ctr)

        
        # plt.imshow(rect, cmap="gray")
        if w*h>1600:
          crop_img = th1[y:y+h, x:x+w]
          
          rect = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
          crop_img = cv2.resize(crop_img, (28, 28), interpolation = cv2.INTER_AREA)
          k+=1
          img_crops.append(crop_img)

    return img_crops, rect

  # input image
  img_path = input("Enter image path: ")
  img = cv2.imread(img_path)
  img_crops, rect = segmentCaptcha(img)

  plt.imshow(rect, cmap = 'gray')
  plt.show()

  img_crops = np.array(img_crops)
  img_crops = torch.Tensor(img_crops)

  l = np.array(['N/A','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z'])

  CAPTCHA = ''
  for img in img_crops:
    img = img.unsqueeze(0)
    img = img.unsqueeze(0)
    outp = letter_model(img)
    outp = torch.squeeze(outp)
    outp = normalize(outp, p=1.0, dim =0)
    pr = torch.argmax(outp)
    captcha = l[pr]
    captcha = captcha.capitalize()
    CAPTCHA = CAPTCHA + captcha
  
  print(CAPTCHA)

